{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75680d00-94ed-4b43-b0ee-ec9bac6c20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup & Imports\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281752ee-c590-46b3-b9bd-f6e65775738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encoder Module\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Transforms input images into a latent embedding z.\"\"\"\n",
    "    def __init__(self, latent_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                  \n",
    "            nn.Conv2d(32, 64, 3, padding=1),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                  \n",
    "            nn.Flatten(),                    \n",
    "        )\n",
    "        self.fc = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.fc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a25f559e-7b63-4bc8-ac62-fb341ab0a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. MemoryController Module\n",
    "class MemoryController:\n",
    "    \"\"\"Decides whether to admit or replace entries in the memory buffer.\"\"\"\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def should_store(self, salience: float, buffer: list) -> bool:\n",
    "        if len(buffer) < self.capacity:\n",
    "            return True\n",
    "        min_r = min(entry['r'] for entry in buffer)\n",
    "        return salience > min_r\n",
    "\n",
    "    def replace_index(self, buffer: list) -> int:\n",
    "        saliences = [entry['r'] for entry in buffer]\n",
    "        return int(np.argmin(saliences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2c038d-f44a-46f0-a93b-6de93414ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. EpisodicMemory Module\n",
    "class EpisodicMemory:\n",
    "    \"\"\"Stores raw episodes (x, z, y, r0, r, tau).\"\"\"\n",
    "    def __init__(self, capacity: int = 1000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []  # list of dicts: {x, z, y, r0, r, tau}\n",
    "\n",
    "    def add(self, entry: dict):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(entry)\n",
    "        else:\n",
    "            idx = entry.pop('replace_idx', None)\n",
    "            if idx is not None:\n",
    "                self.memory[idx] = entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8fafc9-f3bc-4cbf-a7aa-2ffe876c8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. RecallEngine Module\n",
    "class RecallEngine:\n",
    "    \"\"\"Handles salience decay, scoring, and top-k retrieval from EpisodicMemory.\"\"\"\n",
    "    def __init__(self, memory: EpisodicMemory, decay_rate: float = 1e-3, top_k: int = 5):\n",
    "        self.memory = memory\n",
    "        self.decay_rate = decay_rate\n",
    "        self.top_k = top_k\n",
    "        self.controller = MemoryController(memory.capacity)\n",
    "\n",
    "    def recall(self, query_z: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.memory.memory:\n",
    "            return torch.zeros_like(query_z)\n",
    "        now = time.time()\n",
    "        scores = []\n",
    "        for entry in self.memory.memory:\n",
    "            delta_t = now - entry['tau']\n",
    "            entry['r'] = entry['r0'] * np.exp(-self.decay_rate * delta_t)\n",
    "            sim = F.cosine_similarity(\n",
    "                query_z.unsqueeze(0), entry['z'].to(query_z.device).unsqueeze(0), dim=1\n",
    "            )[0]\n",
    "            scores.append((sim * entry['r']).item())\n",
    "        k = min(self.top_k, len(scores))\n",
    "        idxs = np.argsort(scores)[-k:]\n",
    "        recall_vec = torch.stack([\n",
    "            self.memory.memory[i]['z'].to(query_z.device) for i in idxs\n",
    "        ]).mean(dim=0)\n",
    "        return recall_vec\n",
    "\n",
    "    def store(self, x, z, y, salience: float):\n",
    "        entry = {\n",
    "            'x': x.detach().cpu(),\n",
    "            'z': z.detach().cpu(),\n",
    "            'y': y.detach().cpu(),\n",
    "            'r0': salience,\n",
    "            'r': salience,\n",
    "            'tau': time.time(),\n",
    "        }\n",
    "        if self.controller.should_store(salience, self.memory.memory):\n",
    "            if len(self.memory.memory) < self.memory.capacity:\n",
    "                self.memory.memory.append(entry)\n",
    "            else:\n",
    "                entry['replace_idx'] = self.controller.replace_index(self.memory.memory)\n",
    "                self.memory.memory.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06261f95-80a9-4dec-b4d0-b2cf2bacdf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Decoder Module\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Takes latent + recall vectors â†’ class logits.\"\"\"\n",
    "    def __init__(self, latent_dim: int = 128, recall_dim: int = 128, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim + recall_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor, recall_vec: torch.Tensor) -> torch.Tensor:\n",
    "        return self.classifier(torch.cat([z, recall_vec], dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b3699e-dc2d-49e2-8d9d-8d094ce7a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. EpiNetModel Assembly\n",
    "class EpiNetModel(nn.Module):\n",
    "    \"\"\"Orchestrates encoding, episodic storage, recall, and decoding.\"\"\"\n",
    "    def __init__(self, latent_dim=128, memory_capacity=1000, decay_rate=1e-3, top_k=5, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.memory = EpisodicMemory(memory_capacity)\n",
    "        self.recaller = RecallEngine(self.memory, decay_rate, top_k)\n",
    "        self.decoder = Decoder(latent_dim, latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        z = self.encoder(x)\n",
    "        recall_vec = self.recaller.recall(z)\n",
    "        logits = self.decoder(z, recall_vec)\n",
    "        return logits, z\n",
    "\n",
    "    def memorize(self, x, z, y, salience: float):\n",
    "        self.recaller.store(x, z, y, salience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b56222-481b-49a0-991c-934359b9397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([4, 10]), Embedding shape: torch.Size([4, 64])\n"
     ]
    }
   ],
   "source": [
    "# 8. Quick Sanity Check\n",
    "model = EpiNetModel(latent_dim=64, memory_capacity=50, top_k=3)\n",
    "dummy = torch.randn(4,1,28,28)\n",
    "logits, z = model(dummy)\n",
    "print(f\"Logits shape: {logits.shape}, Embedding shape: {z.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d64d75-70a2-4d87-bb1e-9a8be97d204c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 64 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, train_losses\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m model, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_split_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 10. Plot Loss Curves\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, vals \u001b[38;5;129;01min\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mtrain_split_mnist\u001b[0;34m(latent_dim, memory_capacity, decay_rate, top_k, num_classes, batch_size, lr, beta, epochs_per_task)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     23\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 24\u001b[0m     logits, z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     loss_main \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, yb)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mmemory:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mEpiNetModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     12\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 13\u001b[0m     recall_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecaller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z, recall_vec)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, z\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mRecallEngine.recall\u001b[0;34m(self, query_z)\u001b[0m\n\u001b[1;32m     17\u001b[0m     entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_rate \u001b[38;5;241m*\u001b[39m delta_t)\n\u001b[1;32m     18\u001b[0m     sim \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcosine_similarity(\n\u001b[1;32m     19\u001b[0m         query_z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(query_z\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mlen\u001b[39m(scores))\n\u001b[1;32m     23\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(scores)[\u001b[38;5;241m-\u001b[39mk:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 64 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# 9. Full Training Loop (Split-MNIST) + Visualization\n",
    "def train_split_mnist(\n",
    "    latent_dim=64, memory_capacity=200, decay_rate=1e-3, top_k=5,\n",
    "    num_classes=10, batch_size=64, lr=1e-3, beta=0.5, epochs_per_task=3\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "    full_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    tasks = [list(range(0,5)), list(range(5,10))]\n",
    "    model = EpiNetModel(latent_dim, memory_capacity, decay_rate, top_k, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = {0: [], 1: []}\n",
    "\n",
    "    for t_idx, classes in enumerate(tasks):\n",
    "        idxs = [i for i, lbl in enumerate(full_train.targets) if int(lbl) in classes]\n",
    "        loader = DataLoader(Subset(full_train, idxs), batch_size=batch_size, shuffle=True)\n",
    "        for ep in range(epochs_per_task):\n",
    "            epoch_loss = 0.0\n",
    "            for xb, yb in loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                logits, z = model(xb)\n",
    "                loss_main = F.cross_entropy(logits, yb)\n",
    "                if model.memory.memory:\n",
    "                    k_sample = min(len(model.memory.memory), batch_size)\n",
    "                    mem_idxs = np.random.choice(len(model.memory.memory), k_sample, replace=False)\n",
    "                    xm = torch.stack([model.memory.memory[i]['x'] for i in mem_idxs]).to(device)\n",
    "                    ym = torch.tensor([model.memory.memory[i]['y'] for i in mem_idxs],\n",
    "                                      dtype=torch.long, device=device)\n",
    "                    logits_mem, _ = model(xm)\n",
    "                    loss_replay = F.cross_entropy(logits_mem, ym)\n",
    "                    loss = loss_main + beta * loss_replay\n",
    "                else:\n",
    "                    loss = loss_main\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.memorize(xb[0], z[0], yb[0], salience=loss_main.item())\n",
    "                epoch_loss += loss.item() * xb.size(0)\n",
    "            avg = epoch_loss / len(idxs)\n",
    "            train_losses[t_idx].append(avg)\n",
    "            print(f\"Task {t_idx} Epoch {ep} Loss: {avg:.4f}\")\n",
    "    return model, train_losses\n",
    "\n",
    "# Run training\n",
    "model, losses = train_split_mnist()\n",
    "\n",
    "# %%\n",
    "# 10. Plot Loss Curves\n",
    "for t, vals in losses.items():\n",
    "    plt.plot(vals, label=f'Task {t}')\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d49dd-53f7-4f78-8530-d9bb70b65b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3_env)",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
