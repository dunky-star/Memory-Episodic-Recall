{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a0816c-d7eb-4407-903d-ef83ea9edcec",
   "metadata": {},
   "source": [
    "# What If Model Memory Is Reorganized Like Human Episodic recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75680d00-94ed-4b43-b0ee-ec9bac6c20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup & Imports\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97892731-e5cb-4769-b376-274af9749d50",
   "metadata": {},
   "source": [
    "# # EpiNet Encoder Module\n",
    "## 1. **Import** the required libraries  \n",
    "## 2. **Define** the `Encoder` class  \n",
    "## 3. **Instantiate** the encoder and inspect its architecture  \n",
    "## 4. **Run** a forward pass on a dummy image to verify output shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "281752ee-c590-46b3-b9bd-f6e65775738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Transforms input images into a latent embedding z.\"\"\"\n",
    "    def __init__(self, latent_dim: int = 128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 28×28 → 28×28\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 28×28 → 14×14\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 14×14 → 14×14\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 14×14 → 7×7\n",
    "            nn.Flatten(),     # → (64*7*7)\n",
    "    )\n",
    "        # Project flattened features to latent_dim\n",
    "        self.project = nn.Linear(64 * 7 * 7, latent_dim)  # → z ∈ ℝᵈ\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(x)\n",
    "        z = self.project(features)\n",
    "        return z # Matches “z ∈ ℝᵈ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e15f635-9301-46ef-bc95-b122c1028420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (project): Linear(in_features=3136, out_features=128, bias=True)\n",
      ")\n",
      "Output shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate encoder to verify\n",
    "encoder = Encoder(latent_dim=128)\n",
    "print(encoder)\n",
    "dummy = torch.randn(1, 1, 28, 28)\n",
    "print(\"Output shape:\", encoder(dummy).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50a867-9da7-48c6-ad37-35f660ccfb7b",
   "metadata": {},
   "source": [
    "# # MemoryController Module\n",
    "# This defines and tests the `MemoryController` class, which computes\n",
    "# biologically‐inspired salience decay:\n",
    "# **Sections:** \n",
    "# 1. Define `MemoryController`  \n",
    "# 2. Instantiate and Inspect  \n",
    "# 3. Test `decay()` with dummy data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3cda62e-cd35-4158-89da-a215bd6cd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. MemoryController Module\n",
    "class MemoryController:\n",
    "    \"\"\"\n",
    "    Computes the biologically-inspired salience decay.\n",
    "    salience_m = r * exp(–α · (τ_now – τ_m))\n",
    "\n",
    "    Notation:\n",
    "      • r      … initial salience score (r₀)\n",
    "      • τ_m    … timestamp when memory m was stored\n",
    "      • α      … decay rate (learnable or fixed)\n",
    "      • salience_m … decayed salience at the current time\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha: float):\n",
    "        \"\"\"\n",
    "        α: decay rate (higher → faster forgetting)\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def decay(self, r: torch.Tensor, tau_m: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "           Apply decay to a batch of memories.\n",
    "\n",
    "        Args:\n",
    "            r      (torch.Tensor): shape [M], initial salience scores for M memories\n",
    "            tau_m  (torch.Tensor): shape [M], stored timestamps (in seconds) for each memory\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor of shape [M]:\n",
    "              current salience_m = r * exp(–α · (τ_now – τ_m))\n",
    "        \"\"\"\n",
    "        #  Current time in seconds, on same device as inputs\n",
    "        tau_now = torch.tensor(time.time(), device=r.device)\n",
    "        #  Δτ = τ_now – τ_m\n",
    "        delta_tau = tau_now - tau_m\n",
    "        #  Apply decay element-wise\n",
    "        salience_m = r * torch.exp(-self.alpha * delta_tau)\n",
    "        return salience_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44836691-cd81-4319-99d0-313f6c83e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MemoryController object at 0x12180fa90>\n"
     ]
    }
   ],
   "source": [
    "# ## Instantiate and Inspect\n",
    "#\n",
    "# Create a `MemoryController` with a chosen decay rate.\n",
    "\n",
    "# %%\n",
    "alpha = 0.1\n",
    "mem_ctrl = MemoryController(alpha=alpha)\n",
    "print(mem_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d5bc970-7e0f-4f50-bb57-a7d139601fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial r:      tensor([1.0000, 0.5000, 2.0000])\n",
      "Timestamps Δτ:  tensor([0., 0., 0.])\n",
      "Decayed salience: tensor([1.0000, 0.5000, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "# Test `decay()` with Dummy Data\n",
    "# Dummy salience scores\n",
    "r = torch.tensor([1.0, 0.5, 2.0], dtype=torch.float32)\n",
    "# Simulate that these memories were stored 0s, 10s, and 20s ago\n",
    "now = time.time()\n",
    "tau_m = torch.tensor([now, now - 10, now - 20], dtype=torch.float32)\n",
    "\n",
    "# Compute decayed saliences\n",
    "decayed = mem_ctrl.decay(r, tau_m)\n",
    "print(\"Initial r:     \", r)\n",
    "print(\"Timestamps Δτ: \", (torch.tensor(time.time()) - tau_m))\n",
    "print(\"Decayed salience:\", decayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a60a8-84ba-4e0d-b7c3-7220fee29454",
   "metadata": {},
   "source": [
    "# # EpisodicMemory Module\n",
    "# This defines and tests the `EpisodicMemory` class, which stores a fixed‑capacity buffer of memories\n",
    "# and evicts the lowest‑salience trace when full.\n",
    "# **Sections:**\n",
    "# 1. Define `EpisodicMemory`  \n",
    "# 2. Instantiate and Inspect  \n",
    "# 3. Test `add()` and Eviction Logic  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2c038d-f44a-46f0-a93b-6de93414ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. EpisodicMemory Module\n",
    "class EpisodicMemory:\n",
    "    \"\"\"\n",
    "    Fixed‑capacity buffer storing tuples, m = (z, c, r₀, τₘ, yₘ).\n",
    "    admitting only the most salient memories over time.\n",
    "    Admission & eviction are driven by current salience decay:\n",
    "      • Admit new memory if under capacity,\n",
    "      • Otherwise evict the memory with lowest decayed salience.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            capacity: int,\n",
    "            latent_dim: int,\n",
    "            decay_rate: float,\n",
    "            device: torch.device\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            capacity (int): maximum number of memories\n",
    "            latent_dim (int): dimensionality of the latent space\n",
    "            decay_rate (float): decay rate for salience decay\n",
    "            device (torch.device): device to store the memory\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.device = device\n",
    "\n",
    "        # Memory buffer (initially empty)\n",
    "        self.z_buffer = torch.empty((0, latent_dim), device=device) # z: [N × d] latent embeddings z\n",
    "        self.c_buffer = torch.empty((0, latent_dim), device=device) # c: [N × d] context vectors\n",
    "        self.r0_buffer = torch.empty((0,), device=device)  # r0: [N] initial salience score r₀\n",
    "        self.tau_buffer = torch.empty((0,), device=device) # timestamps τₘ when stored\n",
    "        self.y_buffer = torch.empty((0,), dtype=torch.long, device=device) # labels yₘ\n",
    "\n",
    "        # Reuse your MemoryController for decay\n",
    "        self.mem_ctrl = MemoryController(decay_rate)\n",
    "\n",
    "    def add(\n",
    "            self,\n",
    "            z: torch.Tensor,\n",
    "            c: torch.Tensor,\n",
    "            r0: float,\n",
    "            y: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Try to admit new memory (z,c,r0,τ,y).\n",
    "        If at capacity, evict the lowest‐decayed‐salience memory.\n",
    "        \"\"\"\n",
    "        # Preparing tensors for concatenation\n",
    "        z = z.detach().to(self.device).view(1, -1)\n",
    "        c = c.detach().to(self.device).view(1, -1)\n",
    "        r0 = torch.tensor([r0], device=self.device)\n",
    "        y = y.detach().to(self.device).view(1)\n",
    "        tau = torch.tensor([time.time()], device=self.device)\n",
    "\n",
    "        # If under capacity, just append/admit\n",
    "        if self.z_buffer.shape[0] < self.capacity:\n",
    "            self._append(z, c, r0, tau, y)\n",
    "            return\n",
    "\n",
    "        # Otherwise compute decayed salience of existing memories\n",
    "        s_existing = self.mem_ctrl.decay(self.r0_buffer, self.tau_buffer)\n",
    "\n",
    "        # If this new memory isn't more salience than the least one, skip\n",
    "        if r0 <= s_existing.min():\n",
    "            return\n",
    "\n",
    "        # Else evict the lowest‐salience and replace it\n",
    "        idx = torch.argmin(s_existing).item()\n",
    "        self._replace(idx, z, c, r0, tau, y)\n",
    "\n",
    "    def _append(self, z, c, r0, tau, y):\n",
    "        \"\"\"Add a new memory at the end of each buffer.\"\"\"\n",
    "        self.z_buffer = torch.cat([self.z_buffer, z], dim=0)\n",
    "        self.c_buffer = torch.cat([self.c_buffer, c], dim=0)\n",
    "        self.r0_buffer = torch.cat([self.r0_buffer, r0], dim=0)\n",
    "        self.tau_buffer = torch.cat([self.tau_buffer, tau], dim=0)\n",
    "        self.y_buffer = torch.cat([self.y_buffer, y], dim=0)\n",
    "\n",
    "\n",
    "    def _replace(self, idx, z, c, r0, tau, y):\n",
    "        \"\"\"Overwrite the memory at index `idx` with the new one.\"\"\"\n",
    "        self.z_buffer[idx] = z\n",
    "        self.c_buffer[idx] = c\n",
    "        self.r0_buffer[idx] = r0\n",
    "        self.tau_buffer[idx] = tau\n",
    "        self.y_buffer[idx] = y\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Reset all buffers to empty.\"\"\"\n",
    "        self.__init__(self.capacity, self.z_buffer.size(1), self.mem_ctrl.alpha, self.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ed48b7-8b93-475d-a05f-55a83aa26092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.EpisodicMemory object at 0x121814550>\n"
     ]
    }
   ],
   "source": [
    "# ## Instantiate and Inspect\n",
    "# Example: capacity=3, latent_dim=4\n",
    "capacity   = 3\n",
    "latent_dim = 4\n",
    "decay_rate = 0.1\n",
    "device = torch.device('cpu')\n",
    "\n",
    "mem = EpisodicMemory(capacity, latent_dim, decay_rate, device)\n",
    "print(mem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f6bb9db-cdfc-4875-b2c6-17335dd78a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding memory 1: buffer size = 1\n",
      "r0_buffer: [1.0]\n",
      "After adding memory 2: buffer size = 2\n",
      "r0_buffer: [1.0, 2.0]\n",
      "After adding memory 3: buffer size = 3\n",
      "r0_buffer: [1.0, 2.0, 3.0]\n",
      "After adding memory 4: buffer size = 3\n",
      "r0_buffer: [4.0, 2.0, 3.0]\n",
      "After adding memory 5: buffer size = 3\n",
      "r0_buffer: [4.0, 5.0, 3.0]\n",
      "\n",
      "Final z_buffer shape: torch.Size([3, 4])\n",
      "Final r0_buffer values: [4.0, 5.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "# ## Test `add()` and Eviction Logic\n",
    "# Create some dummy embeddings and labels\n",
    "for i in range(5):\n",
    "    z = torch.randn(latent_dim)\n",
    "    c = torch.randn(latent_dim)\n",
    "    y = torch.tensor(i % 2)           # binary labels\n",
    "    r0 = float(i + 1)                 # increasing initial salience\n",
    "    mem.add(z, c, r0, y)\n",
    "    print(f\"After adding memory {i+1}: buffer size = {mem.z_buffer.size(0)}\")\n",
    "    print(\"r0_buffer:\", mem.r0_buffer.tolist())\n",
    "\n",
    "# Final contents\n",
    "print(\"\\nFinal z_buffer shape:\", mem.z_buffer.shape)\n",
    "print(\"Final r0_buffer values:\", mem.r0_buffer.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e52fc-9c82-4498-95db-c561fde3f815",
   "metadata": {},
   "source": [
    "# # RecallEngine Module\n",
    "# This defines and tests the `RecallEngine` class, which retrieves the most\n",
    "# salient memories based on cosine similarity with a query and decayed salience.\n",
    "# **Sections:** \n",
    "# 1. Define `RecallEngine`  \n",
    "# 2. Instantiate and Inspect  \n",
    "# 3. Test `recall()` with Dummy Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd8fafc9-f3bc-4cbf-a7aa-2ffe876c8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. RecallEngine Module\n",
    "# - **top_k**: number of highest‑scoring memories to retrieve  \n",
    "# - **RecallScoreₘ** = cos(z_t, cₘ) · salienceₘ  \n",
    "# - **salienceₘ** = r₀ₘ · exp(–α·(τ_now – τₘ))  \n",
    "# - **Recall embedding**: where the sum is over the Top‑K memories.\n",
    "\n",
    "class RecallEngine:\n",
    "    \"\"\"\n",
    "    Handles salience decay, scoring, and top-k retrieval from EpisodicMemory.\n",
    "    Retrieves salient memories based on cosine similarity and decayed salience.\n",
    "\n",
    "    Given a query embedding z_t and stored memories (z_m, c_m, r0_m, τ_m),\n",
    "    computes for each memory:\n",
    "      RecallScore_m = cos(z_t, c_m) * salience_m\n",
    "    where salience_m = r0_m * exp(-α * (τ_now - τ_m)).\n",
    "    Selects Top‑K memories by RecallScore, then computes recall embedding:\n",
    "      r_t = (1 / Σ_i r_i) * Σ_i r_i * z_i,\n",
    "    where r_i is the decayed salience of the selected memories.\n",
    "    \"\"\"\n",
    "    def __init__(self, top_k: int):\n",
    "        \"\"\"\n",
    "        top_k: number of highest‑scoring memories to retrieve.\n",
    "        \"\"\"\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def recall(self, z_query: torch.Tensor, memory: EpisodicMemory) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform memory recall for a batch of query embeddings.\n",
    "\n",
    "        Args:\n",
    "            z_query (torch.Tensor): shape [B, d], query latent embeddings z_t.\n",
    "            memory (EpisodicMemory): contains buffers:\n",
    "              - c_buffer: [N, d] context embeddings c_m\n",
    "              - z_buffer: [N, d] latent embeddings z_m\n",
    "              - r0_buffer: [N]   initial salience r0_m\n",
    "              - tau_buffer: [N]  timestamps τ_m\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: shape [B, d], recall embeddings r_t.\n",
    "        \"\"\"\n",
    "        # Guard for empty memory\n",
    "        if memory.z_buffer.size(0) == 0:\n",
    "            return torch.zeros_like(z_query)\n",
    "\n",
    "        # Compute decayed salience for all stored memories: [N]\n",
    "        salience = memory.mem_ctrl.decay(memory.r0_buffer, memory.tau_buffer)\n",
    "\n",
    "        # Compute cosine similarity: [B, N]\n",
    "        cos_sim = F.cosine_similarity(\n",
    "            z_query.unsqueeze(1),         # [B, 1, d]\n",
    "            memory.c_buffer.unsqueeze(0),   # [1, N, d]\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "        # Compute recall scores for selection: [B, N]\n",
    "        recall_scores = cos_sim * salience.unsqueeze(0)\n",
    "\n",
    "        # Select Top-K indices by recall score: [B, K]\n",
    "        _, top_idx = torch.topk(recall_scores, self.top_k, dim=1)\n",
    "\n",
    "        # Gather salience and latent embeddings of selected memories\n",
    "        salience_topk = salience[top_idx]          # [B, K]\n",
    "        z_topk = memory.z_buffer[top_idx]   # [B, K, d]\n",
    "\n",
    "        # Normalize by sum of salience: weights = r_i / Σ_j r_j\n",
    "        weights = salience_topk / (salience_topk.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        # Weighted sum to form recall embedding: [B, d]\n",
    "        recall_emb = (weights.unsqueeze(-1) * z_topk).sum(dim=1)\n",
    "        return recall_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da280df4-0caa-4138-a308-474e47101195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.EpisodicMemory object at 0x121815cf0>\n",
      "<__main__.RecallEngine object at 0x121816b60>\n"
     ]
    }
   ],
   "source": [
    "# ## Instantiate and Inspect\n",
    "\n",
    "# Set up a small EpisodicMemory and RecallEngine\n",
    "device     = torch.device('cpu')\n",
    "latent_dim = 4\n",
    "capacity   = 5\n",
    "decay_rate = 0.1\n",
    "top_k      = 2\n",
    "\n",
    "memory      = EpisodicMemory(capacity, latent_dim, decay_rate, device)\n",
    "recall_eng  = RecallEngine(top_k=top_k)\n",
    "\n",
    "print(memory)\n",
    "print(recall_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "904beb4e-f7de-4aed-be44-4425cb3925c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored r0_buffer: [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "Query embeddings:\n",
      " tensor([[ 0.5505,  2.0736, -0.5507, -0.7457],\n",
      "        [ 0.2652, -1.1463, -0.9636,  0.6260]])\n",
      "Recall embeddings:\n",
      " tensor([[ 0.8314,  0.4124, -0.0066,  0.7256],\n",
      "        [ 0.4540, -0.4153, -0.2932, -0.3724]])\n"
     ]
    }
   ],
   "source": [
    "# ## Test `recall()` with Dummy Data\n",
    "# - Add 5 dummy memories with increasing initial salience  \n",
    "# - Wait briefly to generate time differences  \n",
    "# - Query with two random embeddings  \n",
    "\n",
    "# %%\n",
    "# Add dummy memories\n",
    "for i in range(5):\n",
    "    z = torch.randn(latent_dim)\n",
    "    c = torch.randn(latent_dim)\n",
    "    y = torch.tensor(i % 3)           # dummy labels\n",
    "    r0 = float(i + 1)                 # salience increasing\n",
    "    memory.add(z, c, r0, y)\n",
    "    time.sleep(0.1)                   # small delay to vary τ_m\n",
    "\n",
    "print(\"Stored r0_buffer:\", memory.r0_buffer.tolist())\n",
    "\n",
    "# Create a batch of 2 query embeddings\n",
    "z_query = torch.randn(2, latent_dim)\n",
    "\n",
    "# Perform recall\n",
    "r_emb = recall_eng.recall(z_query, memory)\n",
    "\n",
    "print(\"Query embeddings:\\n\", z_query)\n",
    "print(\"Recall embeddings:\\n\", r_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb134073-a21c-4862-a83c-576328633572",
   "metadata": {},
   "source": [
    "# # Decoder Module for EpiNet\n",
    "# This defines and tests the `Decoder` class, which takes a latent embedding `z_t`\n",
    "# and a recall embedding `r_t`, concatenates them, and produces class logits via a two-layer MLP.\n",
    "# **Sections:** \n",
    "# 1. Define `Decoder`  \n",
    "# 2. Instantiate and Inspect  \n",
    "# 3. Forward Pass Test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06261f95-80a9-4dec-b4d0-b2cf2bacdf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   - `z_t` ∈ ℝᵈ: latent embedding from the encoder  \n",
    "#   - `r_t` ∈ ℝᵈ: recall embedding from the memory \n",
    "# Concatenate `[z_t; r_t]` → ℝ²ᵈ \n",
    "\n",
    "# 6. Decoder Module\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture-of-Experts Decoder for EpiNet.\n",
    "\n",
    "    Given latent embedding z_t and recall embedding r_t,\n",
    "    concatenates to h_t ∈ ℝ^{2d}, then uses E parallel experts\n",
    "    and a gating network to produce class logits:\n",
    "      • Gate: g = softmax(G·h_t) ∈ ℝ^E\n",
    "      • Experts: ℓ^{(e)} = expert_e(h_t) ∈ ℝ^K\n",
    "      • logits = Σ_{e=1}^E g_e · ℓ^{(e)}\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_classes: int,\n",
    "        num_experts: int = 4\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_experts = num_experts\n",
    "        # Gating network: 2d → E\n",
    "        self.gate = nn.Linear(latent_dim * 2, num_experts)\n",
    "        # Experts: each maps 2d → hidden_dim → num_classes\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(latent_dim * 2, hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(hidden_dim, num_classes)\n",
    "            ) for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "    def forward(self, z: torch.Tensor, r: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          z (torch.Tensor): [B, d], latent embedding from Encoder\n",
    "          r (torch.Tensor): [B, d], recall embedding from RecallEngine\n",
    "        Returns:\n",
    "          logits (torch.Tensor): [B, num_classes]\n",
    "        \"\"\"\n",
    "        # Concatenate embeddings: [B, 2d]\n",
    "        h = torch.cat([z, r], dim=1)\n",
    "        # Compute gating weights: [B, E]\n",
    "        gate_logits = self.gate(h)\n",
    "        gate_weights = F.softmax(gate_logits, dim=1)\n",
    "        # Expert outputs: stack into [B, E, K]\n",
    "        expert_outputs = torch.stack(\n",
    "            [expert(h) for expert in self.experts],\n",
    "            dim=1\n",
    "        )\n",
    "        # Weighted sum of experts: [B, K]\n",
    "        gate_weights = gate_weights.unsqueeze(-1)  # [B, E, 1]\n",
    "        logits = (gate_weights * expert_outputs).sum(dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37d48e33-dd26-41fc-8e23-fc9493bb0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (gate): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (experts): ModuleList(\n",
      "    (0-3): 4 x Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=256, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ## 3. Instantiate and Inspect\n",
    "\n",
    "latent_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 10\n",
    "\n",
    "decoder = Decoder(latent_dim, hidden_dim, num_classes)\n",
    "print(decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23a0906b-0761-419b-848c-a1f92643e6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_dummy shape: torch.Size([4, 128])\n",
      "r_dummy shape: torch.Size([4, 128])\n",
      "logits shape: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "# ## Forward Pass Test\n",
    "# Verify that concatenating two random embeddings produces correct logits shape.\n",
    "\n",
    "# Dummy embeddings\n",
    "z_dummy = torch.randn(4, latent_dim)  # batch size 4\n",
    "r_dummy = torch.randn(4, latent_dim)\n",
    "\n",
    "# Forward pass\n",
    "logits = decoder(z_dummy, r_dummy)\n",
    "print(\"z_dummy shape:\", z_dummy.shape)\n",
    "print(\"r_dummy shape:\", r_dummy.shape)\n",
    "print(\"logits shape:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b3699e-dc2d-49e2-8d9d-8d094ce7a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. EpiNetModel Assembly\n",
    "class EpiNetModel(nn.Module):\n",
    "    \"\"\"Orchestrates encoding, episodic storage, recall, and decoding.\"\"\"\n",
    "    def __init__(self, latent_dim=128, memory_capacity=1000, decay_rate=1e-3, top_k=5, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.memory = EpisodicMemory(memory_capacity)\n",
    "        self.recaller = RecallEngine(self.memory, decay_rate, top_k)\n",
    "        self.decoder = Decoder(latent_dim, latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        z = self.encoder(x)\n",
    "        recall_vec = self.recaller.recall(z)\n",
    "        logits = self.decoder(z, recall_vec)\n",
    "        return logits, z\n",
    "\n",
    "    def memorize(self, x, z, y, salience: float):\n",
    "        self.recaller.store(x, z, y, salience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b56222-481b-49a0-991c-934359b9397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([4, 10]), Embedding shape: torch.Size([4, 64])\n"
     ]
    }
   ],
   "source": [
    "# 8. Quick Sanity Check\n",
    "model = EpiNetModel(latent_dim=64, memory_capacity=50, top_k=3)\n",
    "dummy = torch.randn(4,1,28,28)\n",
    "logits, z = model(dummy)\n",
    "print(f\"Logits shape: {logits.shape}, Embedding shape: {z.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d64d75-70a2-4d87-bb1e-9a8be97d204c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 64 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, train_losses\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m model, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_split_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 10. Plot Loss Curves\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, vals \u001b[38;5;129;01min\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mtrain_split_mnist\u001b[0;34m(latent_dim, memory_capacity, decay_rate, top_k, num_classes, batch_size, lr, beta, epochs_per_task)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     23\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 24\u001b[0m     logits, z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     loss_main \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, yb)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mmemory:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mEpiNetModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     12\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 13\u001b[0m     recall_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecaller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z, recall_vec)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, z\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mRecallEngine.recall\u001b[0;34m(self, query_z)\u001b[0m\n\u001b[1;32m     17\u001b[0m     entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_rate \u001b[38;5;241m*\u001b[39m delta_t)\n\u001b[1;32m     18\u001b[0m     sim \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcosine_similarity(\n\u001b[1;32m     19\u001b[0m         query_z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(query_z\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mlen\u001b[39m(scores))\n\u001b[1;32m     23\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(scores)[\u001b[38;5;241m-\u001b[39mk:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 64 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# 9. Full Training Loop (Split-MNIST) + Visualization\n",
    "def train_split_mnist(\n",
    "    latent_dim=64, memory_capacity=200, decay_rate=1e-3, top_k=5,\n",
    "    num_classes=10, batch_size=64, lr=1e-3, beta=0.5, epochs_per_task=3\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "    full_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    tasks = [list(range(0,5)), list(range(5,10))]\n",
    "    model = EpiNetModel(latent_dim, memory_capacity, decay_rate, top_k, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = {0: [], 1: []}\n",
    "\n",
    "    for t_idx, classes in enumerate(tasks):\n",
    "        idxs = [i for i, lbl in enumerate(full_train.targets) if int(lbl) in classes]\n",
    "        loader = DataLoader(Subset(full_train, idxs), batch_size=batch_size, shuffle=True)\n",
    "        for ep in range(epochs_per_task):\n",
    "            epoch_loss = 0.0\n",
    "            for xb, yb in loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                logits, z = model(xb)\n",
    "                loss_main = F.cross_entropy(logits, yb)\n",
    "                if model.memory.memory:\n",
    "                    k_sample = min(len(model.memory.memory), batch_size)\n",
    "                    mem_idxs = np.random.choice(len(model.memory.memory), k_sample, replace=False)\n",
    "                    xm = torch.stack([model.memory.memory[i]['x'] for i in mem_idxs]).to(device)\n",
    "                    ym = torch.tensor([model.memory.memory[i]['y'] for i in mem_idxs],\n",
    "                                      dtype=torch.long, device=device)\n",
    "                    logits_mem, _ = model(xm)\n",
    "                    loss_replay = F.cross_entropy(logits_mem, ym)\n",
    "                    loss = loss_main + beta * loss_replay\n",
    "                else:\n",
    "                    loss = loss_main\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.memorize(xb[0], z[0], yb[0], salience=loss_main.item())\n",
    "                epoch_loss += loss.item() * xb.size(0)\n",
    "            avg = epoch_loss / len(idxs)\n",
    "            train_losses[t_idx].append(avg)\n",
    "            print(f\"Task {t_idx} Epoch {ep} Loss: {avg:.4f}\")\n",
    "    return model, train_losses\n",
    "\n",
    "# Run training\n",
    "model, losses = train_split_mnist()\n",
    "\n",
    "# %%\n",
    "# 10. Plot Loss Curves\n",
    "for t, vals in losses.items():\n",
    "    plt.plot(vals, label=f'Task {t}')\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d49dd-53f7-4f78-8530-d9bb70b65b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3_env)",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
